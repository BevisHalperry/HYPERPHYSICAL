<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-15 Fri 21:06 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>HYPERPHYSICAL</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Bevis" />
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org73ac316">1. Project HYPERPHYSICAL*</a>
<ul>
<li><a href="#sec:overview">1.1. Description and Overview</a></li>
<li><a href="#sec:context">1.2. Context and Research</a></li>
<li><a href="#orga33b844">1.3. Technology and Fabrication</a></li>
<li><a href="#org143b04b">1.4. Development and Planning</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org73ac316" class="outline-2">
<h2 id="org73ac316"><span class="section-number-2">1</span> Project HYPERPHYSICAL*</h2>
<div class="outline-text-2" id="text-1">
<p>
<b><i><i>ˌhaɪpəˈfɪzɪkəl</i></i> (*HYP</b>)erphysical (<b>E</b>)nviromental (<b>R</b>)emote (<b>P</b>)resence of (<b>HY</b>)drology, (<b>S</b>)pace, (<b>I</b>)ncalescence, (<b>C</b>)olour (<b>A</b>)nd (<b>L</b>)ight
Remotely gathering environmental and atmospheric data from a location and expressing the data in a tactile, playful and insightful way.
</p>
</div>

<div id="outline-container-org5a14e16" class="outline-3">
<h3 id="sec:overview"><a id="org5a14e16"></a><span class="section-number-3">1.1</span> Description and Overview</h3>
<div class="outline-text-3" id="text-sec:overview">
<p>
This project proposes a system to explore the idea of Environmental Remote Presence or Environmental Telepresence.
In contrast to traditional remote presence where an individuals "presence" is transfered across a distance digitally usually through audio, video and occasionally haptic data,
Environmental Remote Presence transfers an area or locations presence across a distance digitally not just through audio and video data but also through environmental data such
as temprature, humidity, sky colour and visibility. 
This presence could be unidirectional or omnidirectional in nature, HYPERPHYSICAL is focused on unidirectional in the intrest of development time and cost, but only requires
horizontal scaling to make the presence transfer both ways. 
</p>

<p>
HYPERPHYSICAL will take the form of 3 interlinked subsystems:
</p>

<ul class="org-ul">
<li><b>Sensing Sub-System</b>. A ruggedised, self-sustaining and unobtrusive sensing platform using off-the-shelf electronics which will gather environmental data using a suite of sensors and</li>
</ul>
<p>
wirelessly transmit that data to the&#x2026; 
</p>
<ul class="org-ul">
<li><b>Data Pipeline Sub-System</b>. A cloud-based (hopefully self-hosted) system which will parse, sanitise, store/publish and prepare the data for analysis or expression on the&#x2026;</li>
<li><b>Remote Ubication Expression Sub-System</b>. A device which expresses the data in a tactile, playful and insightful way. This may consist of LED's expressing the colour of the sky,</li>
</ul>
<p>
mini fog machines expressing humidity, fans expressing wind-speed and Peltier modules expressing temperature.
</p>
</div>


<div id="outline-container-org9da6678" class="outline-4">
<h4 id="org9da6678"><span class="section-number-4">1.1.1</span> Intended User Experience</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
The first and foremost intention of HYPERPHYSICAL is to attempt to make the intangible "nature" of an remote environment tangible to a person through quantifying,transmitting and 
expressing the natural properties of an environment. With the goal of improving and strengthening our relationship to the natural world and to explore ecological hyper-objects such
as climate change and other effects of the modern Anthropocene. 
</p>

<p>
Secondarily it could be used as:
</p>
<ul class="org-ul">
<li>a tool for climate activism through the idea that without a connection to, or even just a reminder of, an non-urbanised environment it becomes harder to act in the best interests of ecology.</li>
<li>a tool for improving mental health through the idea that exposure to natural environments improves our mental well-being.</li>
<li>a tool for education to show through tactile and novel expression abstract values such as humidity, temperature and wind-speed.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-orgdb3a3f6" class="outline-3">
<h3 id="sec:context"><a id="orgdb3a3f6"></a><span class="section-number-3">1.2</span> Context and Research</h3>
<div class="outline-text-3" id="text-sec:context">
</div>

<div id="outline-container-orga3b4fda" class="outline-4">
<h4 id="orga3b4fda"><span class="section-number-4">1.2.1</span> Concepts and Terms</h4>
<div class="outline-text-4" id="text-1-2-1">
</div>
<ul class="org-ul">
<li><a id="org399ae63"></a>Remote Presence<br /></li>
<li><a id="org7094124"></a>Ecological Dataism<br /></li>

<li><a id="org3ad97c7"></a>Playful Architecture<br /></li>

<li><a id="org157aafc"></a>Unobtrusive sensing<br />
<div class="outline-text-5" id="text-org157aafc">
<ul class="org-ul">
<li>Reliability</li>
<li>Non-toxic</li>
</ul>
</div>
</li>
<li><a id="org181aa71"></a>Hyperobjects<br /></li>
<li><a id="org2c68d70"></a>Environmental art<br /></li>
<li><a id="org2ae97d9"></a>Environmental sensing<br /></li>
<li><a id="org2d34dab"></a>Ecological Activism<br /></li>
</ul>
</div>

<div id="outline-container-orgb520e03" class="outline-4">
<h4 id="orgb520e03"><span class="section-number-4">1.2.2</span> Inspiration and Similar Projects</h4>
<div class="outline-text-4" id="text-1-2-2">
</div>
<ul class="org-ul">
<li><a id="org5417619"></a><a href="http://datawalking.com/">DATA WALKING</a><br />
<div class="outline-text-5" id="text-org5417619">
<p>
A paper based analog collection system for ecological data facilitated through walking
</p>
</div>
</li>
<li><a id="org15474e1"></a><a href="https://citizensense.net/">Home | Citizen Sense</a><br />
<div class="outline-text-5" id="text-org15474e1">
<p>
A series of projects democratising and making accessable environmental data collection for Wild and Urban areas and Pollution monitoring.
</p>
</div>
</li>
<li><a id="org232ec0b"></a><a href="http://jones-bulley.com/living-symphonies/">Living Symphonies (Daniel Jones and James Bulley)</a><br />
<div class="outline-text-5" id="text-org232ec0b">
<p>
A project which augments a natural landscape with the sonification of flora and fauna.
</p>
</div>
</li>
<li><a id="org34eedb0"></a><a href="http://jones-bulley.com/vespers/">Vespers (James Bulley and Daniel Jones)</a><br />
<div class="outline-text-5" id="text-org34eedb0">
<p>
A sound installation that composes a musical score in real-time, drawn from the online activity of the United Kingdom
</p>
</div>
</li>
<li><a id="orge46d5f1"></a><a href="http://www.sara-rodrigues.com/degrees-of-abstraction.html">Degrees of Abstraction - SARA RODRIGUES</a><br />
<div class="outline-text-5" id="text-orge46d5f1">
<p>
A performative installation where the participant explores physical manifestations of graphs displaying environment data.
</p>
</div>
</li>
<li><a id="org6b4b2ff"></a><a href="https://robsweere.com/2012/01/28/styx-2/">STYX – Rob Sweere</a><br />
<div class="outline-text-5" id="text-org6b4b2ff">
<p>
A art peice part of the Hinterland Projects where people places a coin on their head and fixed their gaze on the sky.
</p>
</div>
</li>

<li><a id="org28357b3"></a><a href="http://www.stanza.co.uk/sensity/">Sensity by Stanza</a><br />
<div class="outline-text-5" id="text-org28357b3">
<p>
A series of artworks based on monitoring city spaces. The results are visualisations and sonifications of environmental data made using custom built wireless sensor networks.
</p>
</div>
</li>
<li><a id="org2f58176"></a><a href="https://www.media.mit.edu/projects/tidmarsh-living-observatory-portal/overview/">Tidmarsh Living Observatory Portal — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org2f58176">
<p>
A research project that focuses on the design and fabrication of a pavilion that will generate an immersive physical telepresence experience of a natural wetland.
</p>
</div>
</li>
<li><a id="orgb1bb08c"></a><a href="https://www.media.mit.edu/projects/haptic-footprint/overview/">Haptic Footprint — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orgb1bb08c">
<blockquote>
<p>
Can we augment a stroll through nature with sensory experiences usually outside the range of our perception? Haptic Footprints explore using vibrotactile rendering for this purpose."
</p>
</blockquote>
</div>
</li>
<li><a id="orgc591c32"></a><a href="https://www.media.mit.edu/projects/living-observatory-sensor-networks-for-documenting-and-experiencing-ecology/overview/">Living Observatory: Sensor networks for documenting and experiencing ecology — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orgc591c32">
<blockquote>
<p>
Living Observatory is an initiative for documenting and interpreting ecological change that will allow people, individually and collectively,
 to better understand relationships between ecological processes, human lifestyle choices, and climate change adaptation."
The overarching project of the MIT Responsive Environment Lab in 2018, other projects from it are found here.
</p>
</blockquote>
</div>
</li>

<li><a id="orgeb431e6"></a><a href="https://www.media.mit.edu/projects/low-power-wireless-environmental-sensor-node/overview/">Low-power wireless environmental sensor network — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orgeb431e6">
<p>
The environmental sensor network behind many of the MIT Responsive Environments Tidmarsh project.
</p>
</div>
</li>
<li><a id="org8a9b471"></a><a href="https://www.media.mit.edu/projects/doppelmarsh-cross-reality-environmental-sensor-data-browser/overview/">Doppelmarsh: Cross-reality environmental sensor data browser — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org8a9b471">
<blockquote>
<p>
Doppelmarsh is a cross-reality sensor data browser built for experimenting with presence and multimodal sensory experiences. 
Built on evolving terrain data from a physical wetland landscape, the software integrates real-time data from an environmental sensor network with real-time audio streams 
and other media from the site. Sensor data is rendered in the scene in both visual representations and as 3D sonification. 
Users can explore this data by walking on the virtual terrain in a first person view, or flying high above it. This flexibility allows Doppelmarsh to serve as an interface 
to other research platforms on the site, such as Quadrasense, an augmented reality UAV system that blends a flying live camera view with a virtual camera from Doppelmarsh. 
We are currently investigating methods for representing subsurface data, such as soil and water temperatures at depth, as well as automation in scene and terrain painting.
</p>
</blockquote>
</div>
</li>
<li><a id="org057b3ba"></a><a href="https://www.media.mit.edu/projects/listentree-audio-haptic-display-in-the-natural-environment/overview/">Overview ‹ ListenTree: Audio-haptic display in the natural environment — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org057b3ba">
<p>
A tree that conducts sounds coming from a remote wetland. 
</p>
<blockquote>
<p>
Our intervention is motivated by a need for forms of display that fade into the background, inviting attention rather than requiring it. We consume most digital information through devices that alienate us from our surroundings;
ListenTree points to a future where digital information might become enmeshed in material.
</p>
</blockquote>
</div>
</li>
</ul>
</div>
</div>


<div id="outline-container-orga33b844" class="outline-3">
<h3 id="orga33b844"><span class="section-number-3">1.3</span> Technology and Fabrication</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-orge5581f7" class="outline-4">
<h4 id="orge5581f7"><span class="section-number-4">1.3.1</span> Sensing Sub-System</h4>
<div class="outline-text-4" id="text-1-3-1">
</div>
<ul class="org-ul">
<li><a id="org723c67d"></a>Microcontroller<br />
<div class="outline-text-5" id="text-org723c67d">
<ul class="org-ul">
<li>low cost</li>
<li>low energy</li>
</ul>
</div>
</li>

<li><a id="org8e9ed2d"></a>Connectivity<br /></li>
<li><a id="org89a9887"></a>Atmospheric sensors<br /></li>

<li><a id="org7640c8b"></a>Soil sensors<br /></li>

<li><a id="org4c6dfc6"></a>Colour sensor<br /></li>
</ul>
</div>


<div id="outline-container-org3b87713" class="outline-4">
<h4 id="org3b87713"><span class="section-number-4">1.3.2</span> Data Pipeline Sub-System</h4>
</div>


<div id="outline-container-org2916bdc" class="outline-4">
<h4 id="org2916bdc"><span class="section-number-4">1.3.3</span> Remote Ubication Expression Sub-System (RUESS)</h4>
<div class="outline-text-4" id="text-1-3-3">
<ul class="org-ul">
<li>Interactive</li>
<li>Informing</li>
<li>Connecting</li>
<li>Expressive</li>
<li>Tactile</li>
</ul>
</div>

<ul class="org-ul">
<li><a id="org4c737ab"></a>3D printing<br /></li>
</ul>
</div>
</div>


<div id="outline-container-org143b04b" class="outline-3">
<h3 id="org143b04b"><span class="section-number-3">1.4</span> Development and Planning</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org1dc04cb" class="outline-4">
<h4 id="org1dc04cb"><span class="section-number-4">1.4.1</span> Timeline and Milestones</h4>
</div>

<div id="outline-container-org8e62781" class="outline-4">
<h4 id="org8e62781"><span class="section-number-4">1.4.2</span> Potential Issues and Contingencies</h4>
</div>

<div id="outline-container-org4179d0c" class="outline-4">
<h4 id="org4179d0c"><span class="section-number-4">1.4.3</span> Required Knowledge</h4>
</div>

<div id="outline-container-org30a5a60" class="outline-4">
<h4 id="org30a5a60"><span class="section-number-4">1.4.4</span> Required Learning</h4>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Bevis</p>
<p class="date">Created: 2019-11-15 Fri 21:06</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
