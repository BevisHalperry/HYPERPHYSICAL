<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-15 Fri 20:55 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>HYPERPHYSICAL</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Bevis" />
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgc18c666">1. Project HYPERPHYSICAL*</a>
<ul>
<li><a href="#sec:overview">1.1. Description and Overview</a></li>
<li><a href="#sec:context">1.2. Context and Research</a></li>
<li><a href="#org0196ff4">1.3. Technology and Fabrication</a></li>
<li><a href="#org992c0a5">1.4. Development and Planning</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgc18c666" class="outline-2">
<h2 id="orgc18c666"><span class="section-number-2">1</span> Project HYPERPHYSICAL*</h2>
<div class="outline-text-2" id="text-1">
<p>
<b><i><i>ˌhaɪpəˈfɪzɪkəl</i></i> (*HYP</b>)erphysical (<b>E</b>)nviromental (<b>R</b>)emote (<b>P</b>)resence of (<b>HY</b>)drology, (<b>S</b>)pace, (<b>I</b>)ncalescence, (<b>C</b>)olour (<b>A</b>)nd (<b>L</b>)ight<br />
Remotely gathering environmental and atmospheric data from a location and expressing the data in a tactile, playful and insightful way.<br />
</p>
</div>

<div id="outline-container-org1d9f1f0" class="outline-3">
<h3 id="sec:overview"><a id="org1d9f1f0"></a><span class="section-number-3">1.1</span> Description and Overview</h3>
<div class="outline-text-3" id="text-sec:overview">
<p>
This project proposes a system to explore the idea of Environmental Remote Presence or Environmental Telepresence.<br />
In contrast to traditional remote presence where an individuals "presence" is transfered across a distance digitally usually through audio, video and occasionally haptic data,<br />
Environmental Remote Presence transfers an area or locations presence across a distance digitally not just through audio and video data but also through environmental data such<br />
as temprature, humidity, sky colour and visibility.<br />
This presence could be unidirectional or omnidirectional in nature, HYPERPHYSICAL is focused on unidirectional in the intrest of development time and cost, but only requires<br />
horizontal scaling to make the presence transfer both ways.<br />
</p>

<p>
HYPERPHYSICAL will take the form of 3 interlinked subsystems:<br />
</p>

<ul class="org-ul">
<li><b>Sensing Sub-System</b>. A ruggedised, self-sustaining and unobtrusive sensing platform using off-the-shelf electronics which will gather environmental data using a suite of sensors<br /></li>
</ul>
<p>
and wirelessly transmit that data to the&#x2026;<br />
</p>

<ul class="org-ul">
<li><b>Data Pipeline Sub-System</b>. A cloud-based (hopefully self-hosted) system which will parse, sanitise, store/publish and prepare the data for analysis or expression on the&#x2026;<br /></li>

<li><b>Remote Ubication Expression Sub-System</b>. A device which expresses the data in a tactile, playful and insightful way. This may consist of LED's expressing the colour of the sky,<br /></li>
</ul>
<p>
mini fog machines expressing humidity, fans expressing wind-speed and Peltier modules expressing temperature.<br />
</p>
</div>


<div id="outline-container-orgb4f0884" class="outline-4">
<h4 id="orgb4f0884"><span class="section-number-4">1.1.1</span> Intended User Experience</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
The first and foremost intention of HYPERPHYSICAL is to attempt to make the intangible "nature" of an remote environment tangible to a person through quantifying,transmitting and<br />
expressing the natural properties of an environment. With the goal of improving and strengthening our relationship to the natural world and to explore ecological hyper-objects such<br />
as climate change and other effects of the modern Anthropocene.<br />
</p>

<p>
Secondarily it could be used as:<br />
</p>
<ul class="org-ul">
<li>a tool for climate activism through the idea that without a connection to, or even just a reminder of, an non-urbanised environment it becomes harder to act in the best interests of ecology.<br /></li>
<li>a tool for improving mental health through the idea that exposure to natural environments improves our mental well-being.<br /></li>
<li>a tool for education to show through tactile and novel expression abstract values such as humidity, temperature and wind-speed.<br /></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org3900b92" class="outline-3">
<h3 id="sec:context"><a id="org3900b92"></a><span class="section-number-3">1.2</span> Context and Research</h3>
<div class="outline-text-3" id="text-sec:context">
</div>

<div id="outline-container-org16ed37f" class="outline-4">
<h4 id="org16ed37f"><span class="section-number-4">1.2.1</span> Concepts and Terms</h4>
<div class="outline-text-4" id="text-1-2-1">
</div>
<ul class="org-ul">
<li><a id="orgecf285d"></a>Remote Presence<br /></li>
<li><a id="orgdfcac5a"></a>Ecological Dataism<br /></li>

<li><a id="org7779f34"></a>Playful Architecture<br /></li>

<li><a id="orgd7ea431"></a>Unobtrusive sensing<br />
<div class="outline-text-5" id="text-orgd7ea431">
<ul class="org-ul">
<li>Reliability<br /></li>
<li>Non-toxic<br /></li>
</ul>
</div>
</li>

<li><a id="orgc3bb626"></a>Hyperobjects<br /></li>
<li><a id="orgc614659"></a>Environmental art<br /></li>
<li><a id="org7cf1d28"></a>Environmental sensing<br /></li>
<li><a id="org071c1dc"></a>Ecological Activism<br /></li>
</ul>
</div>

<div id="outline-container-org5c45238" class="outline-4">
<h4 id="org5c45238"><span class="section-number-4">1.2.2</span> Inspiration and Similar Projects</h4>
<div class="outline-text-4" id="text-1-2-2">
</div>
<ul class="org-ul">
<li><a id="orgfd426c2"></a><a href="http://datawalking.com/">DATA WALKING</a><br />
<div class="outline-text-5" id="text-orgfd426c2">
<p>
A paper based analog collection system for ecological data facilitated through walking<br />
</p>
</div>
</li>
<li><a id="orga5ed6b9"></a><a href="https://citizensense.net/">Home | Citizen Sense</a><br />
<div class="outline-text-5" id="text-orga5ed6b9">
<p>
A series of projects democratising and making accessable environmental data collection for Wild and Urban areas and Pollution monitoring.<br />
</p>
</div>
</li>
<li><a id="org5ec3ef5"></a><a href="http://jones-bulley.com/living-symphonies/">Living Symphonies (Daniel Jones and James Bulley)</a><br />
<div class="outline-text-5" id="text-org5ec3ef5">
<p>
A project which augments a natural landscape with the sonification of flora and fauna.<br />
</p>
</div>
</li>
<li><a id="org07df724"></a><a href="http://jones-bulley.com/vespers/">Vespers (James Bulley and Daniel Jones)</a><br />
<div class="outline-text-5" id="text-org07df724">
<p>
A sound installation that composes a musical score in real-time, drawn from the online activity of the United Kingdom<br />
</p>
</div>
</li>
<li><a id="org3028355"></a><a href="http://www.sara-rodrigues.com/degrees-of-abstraction.html">Degrees of Abstraction - SARA RODRIGUES</a><br />
<div class="outline-text-5" id="text-org3028355">
<p>
A performative installation where the participant explores physical manifestations of graphs displaying environment data.<br />
</p>
</div>
</li>
<li><a id="org3ae6ee0"></a><a href="https://robsweere.com/2012/01/28/styx-2/">STYX – Rob Sweere</a><br />
<div class="outline-text-5" id="text-org3ae6ee0">
<p>
A art peice part of the Hinterland Projects where people places a coin on their head and fixed their gaze on the sky.<br />
</p>
</div>
</li>

<li><a id="org3af7dc7"></a><a href="http://www.stanza.co.uk/sensity/">Sensity by Stanza</a><br />
<div class="outline-text-5" id="text-org3af7dc7">
<p>
A series of artworks based on monitoring city spaces. The results are visualisations and sonifications of environmental data made using custom built wireless sensor networks.<br />
</p>
</div>
</li>
<li><a id="orga2337ed"></a><a href="https://www.media.mit.edu/projects/tidmarsh-living-observatory-portal/overview/">Tidmarsh Living Observatory Portal — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orga2337ed">
<p>
A research project that focuses on the design and fabrication of a pavilion that will generate an immersive physical telepresence experience of a natural wetland.<br />
</p>
</div>
</li>
<li><a id="orga4d77f9"></a><a href="https://www.media.mit.edu/projects/haptic-footprint/overview/">Haptic Footprint — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orga4d77f9">
<blockquote>
<p>
Can we augment a stroll through nature with sensory experiences usually outside the range of our perception? Haptic Footprints explore using vibrotactile rendering for this purpose."<br />
</p>
</blockquote>
</div>
</li>
<li><a id="org0176da5"></a><a href="https://www.media.mit.edu/projects/living-observatory-sensor-networks-for-documenting-and-experiencing-ecology/overview/">Living Observatory: Sensor networks for documenting and experiencing ecology — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org0176da5">
<blockquote>
<p>
Living Observatory is an initiative for documenting and interpreting ecological change that will allow people, individually and collectively,<br />
 to better understand relationships between ecological processes, human lifestyle choices, and climate change adaptation."<br />
The overarching project of the MIT Responsive Environment Lab in 2018, other projects from it are found here.<br />
</p>
</blockquote>
</div>
</li>

<li><a id="org9a5753e"></a><a href="https://www.media.mit.edu/projects/low-power-wireless-environmental-sensor-node/overview/">Low-power wireless environmental sensor network — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org9a5753e">
<p>
The environmental sensor network behind many of the MIT Responsive Environments Tidmarsh project.<br />
</p>
</div>
</li>
<li><a id="org19d4230"></a><a href="https://www.media.mit.edu/projects/doppelmarsh-cross-reality-environmental-sensor-data-browser/overview/">Doppelmarsh: Cross-reality environmental sensor data browser — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-org19d4230">
<blockquote>
<p>
Doppelmarsh is a cross-reality sensor data browser built for experimenting with presence and multimodal sensory experiences.<br />
Built on evolving terrain data from a physical wetland landscape, the software integrates real-time data from an environmental sensor network with real-time audio streams<br />
and other media from the site. Sensor data is rendered in the scene in both visual representations and as 3D sonification.<br />
Users can explore this data by walking on the virtual terrain in a first person view, or flying high above it. This flexibility allows Doppelmarsh to serve as an interface<br />
to other research platforms on the site, such as Quadrasense, an augmented reality UAV system that blends a flying live camera view with a virtual camera from Doppelmarsh.<br />
We are currently investigating methods for representing subsurface data, such as soil and water temperatures at depth, as well as automation in scene and terrain painting.<br />
</p>
</blockquote>
</div>
</li>
<li><a id="orga817b3e"></a><a href="https://www.media.mit.edu/projects/listentree-audio-haptic-display-in-the-natural-environment/overview/">Overview ‹ ListenTree: Audio-haptic display in the natural environment — MIT Media Lab</a><br />
<div class="outline-text-5" id="text-orga817b3e">
<p>
A tree that conducts sounds coming from a remote wetland.<br />
</p>
<blockquote>
<p>
Our intervention is motivated by a need for forms of display that fade into the background, inviting attention rather than requiring it. We consume most digital information through devices that alienate us from our surroundings;<br />
ListenTree points to a future where digital information might become enmeshed in material.<br />
</p>
</blockquote>
</div>
</li>
</ul>
</div>
</div>


<div id="outline-container-org0196ff4" class="outline-3">
<h3 id="org0196ff4"><span class="section-number-3">1.3</span> Technology and Fabrication</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-orgade550e" class="outline-4">
<h4 id="orgade550e"><span class="section-number-4">1.3.1</span> Sensing Sub-System</h4>
<div class="outline-text-4" id="text-1-3-1">
</div>
<ul class="org-ul">
<li><a id="org23cf39c"></a>Microcontroller<br />
<div class="outline-text-5" id="text-org23cf39c">
<ul class="org-ul">
<li>low cost<br /></li>
<li>low energy<br /></li>
</ul>
</div>
</li>

<li><a id="org141b9ab"></a>Connectivity<br /></li>
<li><a id="org8432c04"></a>Atmospheric sensors<br /></li>

<li><a id="orgd3ba959"></a>Soil sensors<br /></li>

<li><a id="orgbe726f8"></a>Colour sensor<br /></li>
</ul>
</div>


<div id="outline-container-orge87b03c" class="outline-4">
<h4 id="orge87b03c"><span class="section-number-4">1.3.2</span> Data Pipeline Sub-System</h4>
</div>


<div id="outline-container-org305f08a" class="outline-4">
<h4 id="org305f08a"><span class="section-number-4">1.3.3</span> Remote Ubication Expression Sub-System (RUESS)</h4>
<div class="outline-text-4" id="text-1-3-3">
<ul class="org-ul">
<li>Interactive<br /></li>
<li>Informing<br /></li>
<li>Connecting<br /></li>
<li>Expressive<br /></li>
<li>Tactile<br /></li>
</ul>
</div>

<ul class="org-ul">
<li><a id="org5a16e9d"></a>3D printing<br /></li>
</ul>
</div>
</div>


<div id="outline-container-org992c0a5" class="outline-3">
<h3 id="org992c0a5"><span class="section-number-3">1.4</span> Development and Planning</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org0915cbf" class="outline-4">
<h4 id="org0915cbf"><span class="section-number-4">1.4.1</span> Timeline and Milestones</h4>
</div>

<div id="outline-container-orgf619cdf" class="outline-4">
<h4 id="orgf619cdf"><span class="section-number-4">1.4.2</span> Potential Issues and Contingencies</h4>
</div>

<div id="outline-container-org03881d8" class="outline-4">
<h4 id="org03881d8"><span class="section-number-4">1.4.3</span> Required Knowledge</h4>
</div>

<div id="outline-container-org4f96bfe" class="outline-4">
<h4 id="org4f96bfe"><span class="section-number-4">1.4.4</span> Required Learning</h4>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Bevis</p>
<p class="date">Created: 2019-11-15 Fri 20:55</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
